## 内存管理

Linux 通过 **内存管理系统** 管理内存，除了各种进程以外，内核本身也需要内存。

### 1. 内存相关的统计信息

使用 `free` 命令，得到：

![](https://pic.imgdb.cn/item/65dc3b459f345e8d03ed0cb1.jpg)

* `total ` ： 系统搭载的物理内存总量 ( 约 `7.9GB` )。	
* `free`：表面上可用内存量 ( 约 `7.0GB` )。
* `buff/cache` : 缓冲区缓存与页面缓存 ( 约`342 MB` )。
* `available` ：实际可用内存量。本字段的值为 `free` 字段的值加上内存不足，内核可释放的内存量。“可释放的内存” 指缓冲区缓存与页面缓存中的大部分内存，以及内核除此以外的用于其他地方的部分内存 ( 约 `7.1GB` )。

大致为：

![](https://pic.imgdb.cn/item/65dc40d99f345e8d03fb2659.jpg)

同时 `sar -r 1` 可以采集一些内存的相关信息：

![](https://pic.imgdb.cn/item/65dc6ae79f345e8d0364e561.jpg)

| free 命令的字段 | sar -r 命令的字段    |
| --------------- | -------------------- |
| total           | 没有                 |
| free            | kbmemfree            |
| buff/cache      | kbbuffers + kbcached |
| available       | 没有                 |
|                 |                      |

### 2. 内存不足

随着内存使用量增加，可用内存变得越来越少，首先内核会将可释放的内存释放出来：

![](https://pic.imgdb.cn/item/65dc722b9f345e8d0378845e.jpg)

如果内存使用量继续增加，系统就会陷入做什么都缺乏足够的内存，以至于陷入 **内存不足**（Out of memory）。此时内存管理系统会运行 **OOM killer** 的功能，它会选出合适的进程，并将其 `kill` 掉，以释放更多内存。

个人电脑出现 OOM 问题不大，但是如果在商用的系统服务器上出现，则完全不知道 OOM killer 杀掉了哪个程序，因此也有将服务器 `sysctl` 的 `vm.panic_on_oom` 参数从默认的 `0` 调整为 `1`，这样使得发生 OOM 时候强制系统关机。

### 3. 简单的内存分配

本小节，暂时先不谈虚拟内存部分，只讨论简单的分配制度，内核为进程分配内存的时机大致分为以下两种：

* 在创建进程时 (`fork，fork and exec`)
* 在创建完进程后，动态分配内存时

进程被创建后，如果需要更多内存，进程向内核发出用于获取内存的系统调用，提出分配内存的请求。内核收到请求后，会按照请求量在可用内存中分出相应大小的内存，并将这部分内存的起始地址返回给提出请求的进程。·

但是这种模式会引起下列问题：

* 内存碎片化。
* 访问用于其它用途的内存区域。
* 难以执行多任务。

#### 3.1 内存碎片化

例如：

![](https://pic.imgdb.cn/item/65dc837b9f345e8d03ab7175.jpg)

假设上述地址单位为 KB。上述现象(内存碎片化)会导致本来还剩 `300KB` 的内存，却分出 `300KB` 的内存

#### 3.2 访问用于其它用途的内存

上述模式中，进程均可以通过内存地址来访问内核和其它进程所使用的内存，因此容易存在数据被泄露或者损毁的风险，如果内核的数据被损毁，系统将无法运行。

#### 3.3 难以执行多任务

之前我们了解到可执行程序存在一个固定的代码块，数据块的存储起始地址，那么如果计算机按照之前我们提及的模式管理内存，如果同时运行两个相同程序，按道理这两个程序都需要在同一块，这就意味着只能运行一个，然而事实上我们是可以运行多个程序的，另一种放置方式如图所示：

![](https://pic.imgdb.cn/item/65dc85db9f345e8d03b30acc.jpg)

但是此时第 **2** 个程序由于代码和数据指向的内存地址与预期不同而无法执行。

> 引入虚拟内存机制可以解决如上问题。

### 4. 虚拟内存

现代 CPU 搭载 **虚拟内存** 的功能，它使得进程无法直接访问系统搭载的内存，而是通过虚拟地址间接访问，系统搭载的内存的实际地址被称为 **物理地址**，可以通过地址访问的范围称为 **地址空间**

![](https://pic.imgdb.cn/item/65dda5cb9f345e8d030df4b7.jpg)

之前学到的通过 `readelf` 或者 `cat /proc/[pid]/maps` 输出的地址是 **虚拟地址**。进程无法访问真实的内存，不存在直接访问物理地址的方法。

#### 4.1 页表

通过保存放置于内核使用的内存的页表，可以完成虚拟地址到物理地址的转换。虚拟内存中，**所有内存以页为单位划分并且进行管理**，地址转换也以页为单位进行。

页表中，一个页面对应的数据条目称为页表项，页表项记录着虚拟地址与物理地址的对应关系。页面大小取决于 CPU 架构，x86_64 架构中，页面大小为 4KB，这里假设一个页面大小为 100 B(意味着之后的示意图，内存以每个 100 B 划分为一个格子)。

![](https://pic.imgdb.cn/item/65ddac819f345e8d031d5873.jpg)

如果该进程需要访问 $0 \sim 300$ 的虚拟地址，CPU 会根据该进程的页表自动将其转换为相应的物理地址，**无需经过内核的处理**（页表是硬件实现的，以及用于加速的 TLB，软件实现的可能有）。

> Q. 那么基于硬件的模块(实际上这个模块叫，MMU，内存管理单元)，如何在不需要内核的下，甄别出不同的进程，从而切换到相应的页表来实现虚拟地址到实际地址的转换？
>
> A. MMU 的工作流程为：
>
> * **进程切换**：当操作系统进行进程切换时，会更新硬件中的一些寄存器，如页表基址寄存器（Page Table Base Register，PTBR）或者页表长度寄存器（Page Table Length Register，PTLR），以指向新进程的页表。
> * **地址转换**：当一个进程访问内存时，CPU生成的虚拟地址会被MMU处理。MMU会使用当前进程的页表基址（或其他相关信息）来查找对应的页表项，进而将虚拟地址转换为物理地址。
> * **页表基址**：在硬件中，MMU会根据当前进程的页表基址（通常存储在PTBR中）来定位到该进程的页表在内存中的位置。通过这个页表基址，MMU可以访问到正确的页表，从而实现虚拟地址到物理地址的转换。
> * **权限检查**：在进行地址转换的过程中，MMU还会检查页表项中的权限位，以确保进程对该内存区域有合适的访问权限。

如果，上图进程强行访问大于 300 的虚拟地址，则会发生 **地址越界** 问题，如果虚拟地址空间为 500B，形如：

| 虚拟地址 | 物理地址 |
| -------- | -------- |
| 0~100    | 500~600  |
| 100~200  | 600~700  |
| 200~300  | 700~800  |
| 300~400  | x        |
| 400~500  | x        |
|          |          |

此时 300 以上的区域还未分配物理内存，此时访问大于 300 的虚拟地址，会发生 **缺页中断**，缺页中断会终止正在执行的命令，启动内核中的缺页中断机构的处理。

内核的缺页中断机构检测到非法访问，向进程发送 SIGSEGV 信号，接收到该信号的进程通常会被强制结束运行。
#### 4.2 实验

编写一段访问非法地址的程序，程序要求如下：

* 输出字符串 `before invalid access`
* 向必定会访问失败的地址 `NULL` 写入一个值 (这里将写入 0)
* 输出字符串 `after invalid access`

![](https://pic.imgdb.cn/item/65ddb4e89f345e8d03316bd6.jpg)

> 程序对于非法地址进行访问，进而导致内核向进程发送 SIGSEGV 信号，从而导致没有输出 `after invalid access` 程序就退出。

#### 4.3 为进程分配内存

下面阐述，内核如何利用虚拟内存机制为进程分配内存。

##### 1. 创建进程时

首先内核读取可执行文件，根据可执行文件的辅助信息将其 **代码段 + 数据段** 复制到内存上一块大小为 300 的区域，例如：

![](https://pic.imgdb.cn/item/65def3979f345e8d03ee089f.jpg)

当复制完成后，根据当前代码段和数据段在内存的实际地址，创建该进程的页表，将虚拟地址映射到物理地址。

![](https://pic.imgdb.cn/item/65def5c69f345e8d03f367db.jpg)

然后从程序入口处地址 **0**，对应实地址 **500** 开始运行程序。

##### 2. 在动态分配内存

如果进程请求更多内存，内核将为其分配新的内存，创建相应的页表，然后把新分配的内存的物理地址对应的虚拟地址返回给进程，例如：

![](https://pic.imgdb.cn/item/65def6f29f345e8d03f6f941.jpg)

#### 4.4 实验

我们需要实现以下 $3$ 个功能的程序：

* 显示进程的内存映射信息：(`/proc/[pid]/maps` 的输出)
* 额外回获取 `100mb` 的内存
* 再次显示内存映射的信息

> mmap.cpp

```c++
#include <unistd.h>
#include <sys/mman.h>
#include <bits/stdc++.h>
#include <err.h>

constexpr int BUFFER_SIZE = 1000;
constexpr int ALLOC_SIZE = 100 * 1024 * 1024;

static char command[BUFFER_SIZE];

int main() {
        pid_t pid = getpid();
        snprintf(command, BUFFER_SIZE, "cat /proc/%d/maps", pid);

        std::cout << "*** Mem map before allocation ***" << std::endl;
        system(command);

        void *new_memory = mmap(NULL, ALLOC_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);

        if (new_memory == (void *) -1)
                err(EXIT_FAILURE, "mmap() failed");
        std::cout << std::endl;

        printf("*** succeeded to allocate memory: address = %p; size = 0x%x ***\n", new_memory, ALLOC_SIZE);
        std::cout << std::endl;

        std::cout << "*** Mem map after allocation ***" << std::endl;
        system(command);
		
    	// 解除申请的 100mb 的内存
        if (munmap(new_memory, ALLOC_SIZE) == -1)
                        err(EXIT_FAILURE, "munmap() failed");
        return 0;

}
```

> `system()` 实现了一种简单的类似 fork-and-exec 的功能

运行编译后的可执行程序，得到：

```
*** Mem map before allocation ***
...
55c818a13000-55c818a34000 rw-p 00000000 00:00 0                          [heap]
7f3d6c9fd000-7f3d6ca01000 rw-p 00000000 00:00 0
...

*** succeeded to allocate memory: address = 0x7f3d665fd000; size = 0x6400000 ***

*** Mem map after allocation ***
...
55c818a13000-55c818a34000 rw-p 00000000 00:00 0                          [heap]
7f3d665fd000-7f3d6ca01000 rw-p 00000000 00:00 0
....
```

可以发现申请 `100MB` 空间后，`7f3d6c9fd000-7f3d6ca01000` 变成了 `7f3d665fd000-7f3d6ca01000`，多出了内存：

然后通过 

```bash
syz@syz:~/projects/class5$ python3 -c "print(- 0x7f3d665fd000 +  0x7f3d6c9fd000)"
104857600
```

#### 4.5 利用上层进行分配

c 语言中存在一个名为 `malloc` 的函数，也是内存申请相关，Linux 中，该函数底层用到了 `mmap()`

`mmap()` 是以页为单位获取内存的，而 `malloc()` 是以字节为单位获取内存的，为了以字节为单位获取内存，`glibc` 事先通过系统调用 `mmap()` 向内核申请一大块内存区域作为内存池，程序调用 `malloc` ，`glibc` 会划分相应内存给程序，当内存池内存消耗完，`glibc`  会再次调用 `mmap()` 申请新的内存区域。

![](https://pic.imgdb.cn/item/65df07b19f345e8d031f90d0.jpg)



一般来说 Linux 显示进程的内存消耗大于程序统计自身内存消耗量，程序自身内存消耗量一般统计 `malloc()` 申请的那部分，而 LInux 显示的是创建进程消耗的内存，以及进程通过 `mmap()` 分配的所有内存。

> 即使是 python 其底层，仍然是通过 c 语言的 malloc 来获取内存。

#### 4.6 解决问题

**内存碎片化**

只需要设计好页表，就能将物理内存上的碎片整合成虚拟地址空间上的一篇连续的内存区域，类似：

![](https://pic.imgdb.cn/item/65df0f619f345e8d0331f1bc.jpg)

**访问用于其他用途的内存区域**

虚拟地址空间是每个进程独有的，页表也是每个进程独有的，因此进程根本无法访问其它进程的内存，类似：

![](https://pic.imgdb.cn/item/65df105e9f345e8d03345971.jpg)

但是一般处于方便，内核的内存区域被映射到了所有进程的虚拟地址空间中。但是与内核相关的页表项都标有 "内核模式专用"  的信息，只有在 cpu 处于内核模式才能进行访问，因此这部分内存也不会在用户模式下被意外访问，类似：

![](https://pic.imgdb.cn/item/65df11829f345e8d03374957.jpg)

**难以执行多任务**

每个进程拥有独立的虚拟地址空间，不用担心干扰其它程序的运行。
